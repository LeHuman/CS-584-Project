\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{pgfgantt}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{%
    Diffusion Models for Machine Learning \\
    \huge CS 584 Intermediate Report}

\author{\IEEEauthorblockN{1\textsuperscript{st} Isaias Rivera}
    \IEEEauthorblockA{\textit{College of Computing} \\
        \textit{Illinois Institute of Technology}\\
        Chicago, Illinois, USA \\
        irivera3@hawk.iit.edu}
}

\maketitle

% The intermediate project report (3-5 pages) should cover:
% • a high quality introduction and problem description
% • description of the data used in the project
% • what have you done so far
% • what remains to be done

\section{Introduction}

Diffusion models are a type of generative model that utilizes the principles of diffusion to generate realistic data. There are different types of diffusion models
that have the same underlying idea including, diffusion probabilistic models, noise-conditioned score network,
and denoising diffusion probabilistic models \cite{weng2021diffusion}.

The basic idea behind diffusion-based generative models is that noise is first added to an initial input,
where the resulting noisy image is then processed to subsequently remove that noise, while preserving the underlying structure of the image.
This process is done multiple times where, at each step of this process, the noise level is decreased, and the resulting image becomes more and more refined. After this training, the model can then be used to generate data by passing random noise through the learned denoising process.

Diffusion-based generative models can function either unconditionally or guided such as with GLIDE's text-guided diffusion model, trading "diversity for fidelity"\cite{GLIDE}. There are other examples of this online such as with Google's Imagen, and OpenAI's DALL-E 2.

There are many variations\cite{hoCF}\cite{kerasDDPM}\cite{pmlr-v162-nichol22a}\cite{hugimpl} and different improvements\cite{nichol2021improved}\cite{song2022denoising} to diffusion models that are being actively researched and have already been implemented, however, as in my proposal I mainly have wanted to explore implementing my own in an easily digestible format.

\section {Focus}

The main focus of my project has been with Denoising diffusion probabilistic models, or DDPM for short, as I have found the most literature revolving around this variation on diffusion models. I have not gone further than DDPMs as I wanted to to first get some results before moving on. Regardless, the majority of my research has been with understanding both the math and implementation of every step with a DDPM\cite{nain2022-2}\cite{nain2022-3}\cite{ho2020denoising}.

\section {Implementation}

Thus far, I have a very basic implementation of the forward and backward process of a DDPM. For some components of the process I am still working towards fully understanding and developing an easy to understand notebook, however, I do have a working model, albeit, relatively crude and unoptimized.

My main notebook uses torch to implement everything, however, I have found many implementations that use a variety of APIs.

\subsection{The Foward Process}

The forward process is the step that involves adding noise to data. Given a number of timesteps, gaussian noise is added to data at each step, where subsequent steps are dependent on the output of the previous step. The main equation that describes this, is as follows

$$
    q(x_{1:T}\vert x_{0})
    := \prod_{t=1}^{T}q(x_{t}\vert x_{t-1})
    :=\prod_{t=1}^{T}\mathcal{N}(x_{t};\sqrt{1-\beta_{t}} x_{t-1},\ \beta_{t}\bf I)
$$

Where $T$ is the total number of timesteps, $\beta_t$ is the variance schedule, where $\beta_t \in (0,1)$ and $\beta_{1} < \beta_{2}...$, it describes the amount of noise we want to add to each timestep. This schedule can simply be set as linear, 

\subsection{The Reverse Process}



\bibliography{refs}
\bibliographystyle{ieeetr}

\end{document}